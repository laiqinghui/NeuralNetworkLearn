{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import tensorflow as tf\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DOCUMENT_LENGTH = 100\n",
    "N_FILTERS = 10\n",
    "FILTER_SHAPE1 = [20, 256]\n",
    "POOLING_WINDOW = 4\n",
    "POOLING_STRIDE = 2\n",
    "MAX_LABEL = 15\n",
    "\n",
    "no_epochs = 100\n",
    "lr = 0.01\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "seed = 10\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_data_chars():\n",
    "  \n",
    "  x_train, y_train, x_test, y_test = [], [], [], []\n",
    "\n",
    "  with open('train_medium.csv', encoding='utf-8') as filex:\n",
    "    reader = csv.reader(filex)\n",
    "    for row in reader:\n",
    "      x_train.append(row[1])\n",
    "      y_train.append(int(row[0]))\n",
    "\n",
    "  with open('test_medium.csv', encoding='utf-8') as filex:\n",
    "    reader = csv.reader(filex)\n",
    "    for row in reader:\n",
    "      x_test.append(row[1])\n",
    "      y_test.append(int(row[0]))\n",
    "  \n",
    "  x_train = pandas.Series(x_train)\n",
    "  y_train = pandas.Series(y_train)\n",
    "  x_test = pandas.Series(x_test)\n",
    "  y_test = pandas.Series(y_test)\n",
    "  \n",
    "  \n",
    "  char_processor = tf.contrib.learn.preprocessing.ByteProcessor(MAX_DOCUMENT_LENGTH)\n",
    "  x_train = np.array(list(char_processor.fit_transform(x_train)))\n",
    "  x_test = np.array(list(char_processor.transform(x_test)))\n",
    "  y_train = y_train.values\n",
    "  y_test = y_test.values\n",
    "  \n",
    "  return x_train, y_train, x_test, y_test\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def char_cnn_model(x):\n",
    "  \n",
    "  input_layer = tf.reshape(\n",
    "      tf.one_hot(x, 256), [-1, MAX_DOCUMENT_LENGTH, 256, 1])\n",
    "\n",
    "  with tf.variable_scope('CNN_Layer1'):\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        input_layer,\n",
    "        filters=N_FILTERS,\n",
    "        kernel_size=FILTER_SHAPE1,\n",
    "        padding='VALID',\n",
    "        activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(\n",
    "        conv1,\n",
    "        pool_size=POOLING_WINDOW,\n",
    "        strides=POOLING_STRIDE,\n",
    "        padding='SAME')\n",
    "\n",
    "    pool1 = tf.squeeze(tf.reduce_max(pool1, 1), squeeze_dims=[1])\n",
    "\n",
    "  logits = tf.layers.dense(pool1, MAX_LABEL, activation=None)\n",
    "\n",
    "  return input_layer, logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "  tf.reset_default_graph()\n",
    "  \n",
    "  x_train, y_train, x_test, y_test = read_data_chars()\n",
    "\n",
    "  print(len(x_train))\n",
    "  print(len(x_test))\n",
    "\n",
    "  # Create the model\n",
    "  x = tf.placeholder(tf.int64, [None, MAX_DOCUMENT_LENGTH])\n",
    "  y_ = tf.placeholder(tf.int64)\n",
    "\n",
    "  inputs, logits = char_cnn_model(x)\n",
    "\n",
    "  # Optimizer\n",
    "  entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf.one_hot(y_, MAX_LABEL), logits=logits))\n",
    "  train_op = tf.train.AdamOptimizer(lr).minimize(entropy)\n",
    "\n",
    "  sess = tf.Session()\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "\n",
    "  # training\n",
    "  loss = []\n",
    "  for e in range(no_epochs):\n",
    "    _, loss_  = sess.run([train_op, entropy], {x: x_train, y_: y_train})\n",
    "    loss.append(loss_)\n",
    "\n",
    "\n",
    "    if e%1 == 0:\n",
    "      print('iter: %d, entropy: %g'%(e, loss[e]))\n",
    "  \n",
    "  sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600\n",
      "700\n",
      "iter: 0, entropy: 2.70919\n",
      "iter: 1, entropy: 2.686\n",
      "iter: 2, entropy: 2.65402\n",
      "iter: 3, entropy: 2.62072\n",
      "iter: 4, entropy: 2.58592\n",
      "iter: 5, entropy: 2.54927\n",
      "iter: 6, entropy: 2.51049\n",
      "iter: 7, entropy: 2.46986\n",
      "iter: 8, entropy: 2.42803\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
